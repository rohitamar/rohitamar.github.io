<html>
    <head>
        <title>ML/DL Papers I Like</title>
    </head>
    <body>
        <div>
            <h1></h1>
        </div>
        <div>
            <div>
                <h2>Recurrent Neural Networks (RNN)</h2>
                <h3>Encoder Decoder Architectures</h3>
                <h3>Attention -- as it relates to RNN</h3>
                <h3>Long Short Term Networks (LSTM)</h3>
                <h3>Gated Recurrent Unit (GRU)</h3>
            </div>
            <div>
                <h2>Contrastive Representational Learning</h2>
            </div>
            <div>
                <h2>Domain Adaptation</h2>
            </div>
            <div>
                <h2>Recommender Systems</h2>
            </div>
            <div>
                <h2>Training Models</h2>
                <h3>Batch Normalization</h3>
                <h3>Gradient Descent</h3>
            </div>
            <div>
                <h2>Generative Advesarial Networks</h2>

            </div>
            <div>
                <h2>Probabilistic Graphical Models</h2>
            </div>
        </div>
    </body>
    <a href = "https://blog.paperspace.com/busting-the-myths-about-batch-normalization/">Good article on Batch Normalization</a>
    <br>
    <a href = "https://arxiv.org/pdf/1502.03167.pdf">Batch Normalization Paper</a>
    <br>
</html>
